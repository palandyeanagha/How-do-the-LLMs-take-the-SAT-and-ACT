{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1nDYb7azRe41Vs5_MNI0evYjX3iSfrAQq","timestamp":1745028392431}],"gpuType":"A100","authorship_tag":"ABX9TyP9BxhZrM9/OHxu9fuqhbU+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"98d07f484208497490ed71bc22742de8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_591f4b5def524090b44c9cc6c30e1222","IPY_MODEL_dc8fa108ad974c90a7fd0c13d2fffcf5","IPY_MODEL_9ff0fdceb5914a1d8a8c0c75cd927cf5"],"layout":"IPY_MODEL_1a504401fb7148728c7bfc142b45cdf0"}},"591f4b5def524090b44c9cc6c30e1222":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5864ddce9d47402db087bebe04c7066a","placeholder":"​","style":"IPY_MODEL_49470c3e8e524e2d9e6e96ccea6061e5","value":"tokenizer_config.json: 100%"}},"dc8fa108ad974c90a7fd0c13d2fffcf5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bec11c0c352e41b682d90593999f034a","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ca4fbb0e5f84896be9e53c546653fd2","value":26}},"9ff0fdceb5914a1d8a8c0c75cd927cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e50b5bf41a844dcbf82da915ee6b898","placeholder":"​","style":"IPY_MODEL_0f1ed7677a004063ae559b93e08821fd","value":" 26.0/26.0 [00:00&lt;00:00, 3.02kB/s]"}},"1a504401fb7148728c7bfc142b45cdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5864ddce9d47402db087bebe04c7066a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49470c3e8e524e2d9e6e96ccea6061e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bec11c0c352e41b682d90593999f034a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ca4fbb0e5f84896be9e53c546653fd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e50b5bf41a844dcbf82da915ee6b898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f1ed7677a004063ae559b93e08821fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22295b0edf4f491ebd53ca0144ff0511":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e693d74559364200ac5440082dd975dd","IPY_MODEL_2f536c8170f747dc8dd4875c9fe8c31f","IPY_MODEL_0e806e5813054592a00db084309b44da"],"layout":"IPY_MODEL_6cb922ff5489452f9df016d046c3eb23"}},"e693d74559364200ac5440082dd975dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0df2c5c63e14cd9a875cb93be3db86a","placeholder":"​","style":"IPY_MODEL_ab1a8c72770a464fa0334f2c83f5106e","value":"config.json: 100%"}},"2f536c8170f747dc8dd4875c9fe8c31f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1f6caf4d21447e7ba6938937508527f","max":689,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4f13dde07b24ca88242724a3b95a104","value":689}},"0e806e5813054592a00db084309b44da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74ab2becd4e3420eaaa3ed4d3632bac5","placeholder":"​","style":"IPY_MODEL_7eb8985b176c4aaa8b6bc17db318f708","value":" 689/689 [00:00&lt;00:00, 85.9kB/s]"}},"6cb922ff5489452f9df016d046c3eb23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0df2c5c63e14cd9a875cb93be3db86a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab1a8c72770a464fa0334f2c83f5106e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1f6caf4d21447e7ba6938937508527f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4f13dde07b24ca88242724a3b95a104":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74ab2becd4e3420eaaa3ed4d3632bac5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eb8985b176c4aaa8b6bc17db318f708":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78a8d261c4b3414194ac142bc2623543":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1a97e6748084957b6b4d5e3f142ebb7","IPY_MODEL_8d40eac84fa54ae7b985670224565f25","IPY_MODEL_ab2f32ffd85a4b74979c7594e089e2d9"],"layout":"IPY_MODEL_95257940a1bc49e9bfe3c3c610f95496"}},"a1a97e6748084957b6b4d5e3f142ebb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_036b467f58ec4a7b85d9266179b278fc","placeholder":"​","style":"IPY_MODEL_321bdecb600c4b55a82f2ffe2da5ec15","value":"vocab.json: 100%"}},"8d40eac84fa54ae7b985670224565f25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2802bf325124d37a201e21e134a36c3","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67d207297da94e83bc9e679dacd647f9","value":1042301}},"ab2f32ffd85a4b74979c7594e089e2d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f28a2da46040f5b2c6c6df6825c128","placeholder":"​","style":"IPY_MODEL_89be7289dc2244929050496bb93cebd5","value":" 1.04M/1.04M [00:00&lt;00:00, 1.60MB/s]"}},"95257940a1bc49e9bfe3c3c610f95496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"036b467f58ec4a7b85d9266179b278fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"321bdecb600c4b55a82f2ffe2da5ec15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2802bf325124d37a201e21e134a36c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67d207297da94e83bc9e679dacd647f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53f28a2da46040f5b2c6c6df6825c128":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89be7289dc2244929050496bb93cebd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e7f1216a52a427eb8b56cb89c5a6e83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25bf264c58d94ab5b9f941dbd9d4d1da","IPY_MODEL_658942d3e5ee446c92f3b9ec6ecbfad7","IPY_MODEL_2a6775e4c3e14e76a45e410e85da9623"],"layout":"IPY_MODEL_468d65e504ae4934bca7ae9c58cd55b0"}},"25bf264c58d94ab5b9f941dbd9d4d1da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f43f7de436c46a1b70bbae51fadc4cd","placeholder":"​","style":"IPY_MODEL_ab348b677b414c168867d131549a3d04","value":"merges.txt: 100%"}},"658942d3e5ee446c92f3b9ec6ecbfad7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a86460a5224542bdae6ce723156880a4","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4d50cab8eac4adebe9f7e996516743a","value":456318}},"2a6775e4c3e14e76a45e410e85da9623":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d145a61b96d493898310231aa4df629","placeholder":"​","style":"IPY_MODEL_018e0cd1a47e48e9984fdba26b1b2682","value":" 456k/456k [00:00&lt;00:00, 1.07MB/s]"}},"468d65e504ae4934bca7ae9c58cd55b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f43f7de436c46a1b70bbae51fadc4cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab348b677b414c168867d131549a3d04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a86460a5224542bdae6ce723156880a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d50cab8eac4adebe9f7e996516743a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d145a61b96d493898310231aa4df629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"018e0cd1a47e48e9984fdba26b1b2682":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bdb09cdfad1469092b7c33d5820f556":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff44f9aec8d248d593dd69f77cea5211","IPY_MODEL_40fd62266b8846e7a53edaf3e875a505","IPY_MODEL_82990f6207b14da2a4f91fbfbf9461fd"],"layout":"IPY_MODEL_73199331c5294612895c55159505de5f"}},"ff44f9aec8d248d593dd69f77cea5211":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_919a14c564fd4be4aed8a14a6ecab92c","placeholder":"​","style":"IPY_MODEL_dfba311496654a12948fd47e70f9fc24","value":"tokenizer.json: 100%"}},"40fd62266b8846e7a53edaf3e875a505":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f551e29be04a4a37a0f6d46dfe08865c","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4810a63b2644801aafdee6a14d02d0e","value":1355256}},"82990f6207b14da2a4f91fbfbf9461fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7ecc5977924ba7917a51c5358b709a","placeholder":"​","style":"IPY_MODEL_e459a60ad4234b4aaee85d86297d82bd","value":" 1.36M/1.36M [00:00&lt;00:00, 6.01MB/s]"}},"73199331c5294612895c55159505de5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"919a14c564fd4be4aed8a14a6ecab92c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfba311496654a12948fd47e70f9fc24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f551e29be04a4a37a0f6d46dfe08865c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4810a63b2644801aafdee6a14d02d0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be7ecc5977924ba7917a51c5358b709a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e459a60ad4234b4aaee85d86297d82bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2da00f9a91c54a4aa1c732826241f112":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61616548e3264781921ea15d591ddca8","IPY_MODEL_30dd36403e77448bb44d2eff33c454ce","IPY_MODEL_12479fe0c3b8405a99e31f4ed14afcf7"],"layout":"IPY_MODEL_277514f546cf44bead7039904e8d9d6c"}},"61616548e3264781921ea15d591ddca8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a05f1ca2d15247f2b1bc16094721d8e6","placeholder":"​","style":"IPY_MODEL_d1fc8584d65c455e8158ab4299fa8343","value":"generation_config.json: 100%"}},"30dd36403e77448bb44d2eff33c454ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5212ec8600af4a4198f8769dc6811c5e","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6445107cddc44a68b09428779a64441","value":124}},"12479fe0c3b8405a99e31f4ed14afcf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f2c5084a174f88921ea3f17d7d0fc7","placeholder":"​","style":"IPY_MODEL_3b8b141f5648485e94e1f69556eb2945","value":" 124/124 [00:00&lt;00:00, 16.7kB/s]"}},"277514f546cf44bead7039904e8d9d6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a05f1ca2d15247f2b1bc16094721d8e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1fc8584d65c455e8158ab4299fa8343":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5212ec8600af4a4198f8769dc6811c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6445107cddc44a68b09428779a64441":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88f2c5084a174f88921ea3f17d7d0fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b8b141f5648485e94e1f69556eb2945":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80fb81bef91442a8ab95c5b656a760fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0173adad0e2a4a8da83f39cac34d0c90","IPY_MODEL_3aa6ebdaa14f45d5bf8a6578a8d372f8","IPY_MODEL_cfc268ef4e6b42e59b5af120b48cb671"],"layout":"IPY_MODEL_5dc6061025984a19909c4d5302b67d37"}},"0173adad0e2a4a8da83f39cac34d0c90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea559bede34d4be88281f7fbb19f1101","placeholder":"​","style":"IPY_MODEL_a3a78f2385aa443189f3e4e0099fd166","value":"Downloading builder script: 100%"}},"3aa6ebdaa14f45d5bf8a6578a8d372f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c12cb7bec3fc4808b5d3c0fd05e76d33","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2131fec87b56439caa0e37125ec64d15","value":4203}},"cfc268ef4e6b42e59b5af120b48cb671":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1de6c1146aa74d82b90e8cf9fc132337","placeholder":"​","style":"IPY_MODEL_91947b908b604cd08d89f1e6aeba43ff","value":" 4.20k/4.20k [00:00&lt;00:00, 502kB/s]"}},"5dc6061025984a19909c4d5302b67d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea559bede34d4be88281f7fbb19f1101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a78f2385aa443189f3e4e0099fd166":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c12cb7bec3fc4808b5d3c0fd05e76d33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2131fec87b56439caa0e37125ec64d15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1de6c1146aa74d82b90e8cf9fc132337":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91947b908b604cd08d89f1e6aeba43ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9e6acc66b4b41558a982feb58d08667":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a59f7f9b753b40c6b9cf6855ed123a10","IPY_MODEL_1945731621e54137bc0ae16c4e8cde2b","IPY_MODEL_40b3c98c3ea34e3494949b4357d13a09"],"layout":"IPY_MODEL_d7cf226ecf204324b5d2ad490af8d842"}},"a59f7f9b753b40c6b9cf6855ed123a10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf6255e20e524543884b57e7f723b012","placeholder":"​","style":"IPY_MODEL_6d66e498ba93420d8774b0bf56eeda3c","value":"model.safetensors: 100%"}},"1945731621e54137bc0ae16c4e8cde2b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25bfabb1ee074435b958d8cb5d1de3cf","max":6431829964,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58353711b5c9440489c7ab773dfeb321","value":6431829964}},"40b3c98c3ea34e3494949b4357d13a09":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ffd57c065154e8dbc98be217dc848f2","placeholder":"​","style":"IPY_MODEL_5ab2abe6beca427cbea7612705bc0daf","value":" 6.43G/6.43G [00:20&lt;00:00, 377MB/s]"}},"d7cf226ecf204324b5d2ad490af8d842":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf6255e20e524543884b57e7f723b012":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d66e498ba93420d8774b0bf56eeda3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bfabb1ee074435b958d8cb5d1de3cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58353711b5c9440489c7ab773dfeb321":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ffd57c065154e8dbc98be217dc848f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab2abe6beca427cbea7612705bc0daf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4724eda40e0842378378adb62cbd6a9d":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_e19ef2ed343f4756b9f4d5765e4f5877","IPY_MODEL_cf25bae67a5844d4b45f29afe724aea5","IPY_MODEL_025b1e3343094c9bbbea51ca633af1c3","IPY_MODEL_8f5cee23efdd47e4a33dc145619cbbb9","IPY_MODEL_478ea8bae8664b5182726838b6cc402c"],"layout":"IPY_MODEL_21ed730edd9445fda7dd3f03f5c11222"}},"e19ef2ed343f4756b9f4d5765e4f5877":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ff7c671e7564bcdb1d2b9d5ee3019c5","placeholder":"​","style":"IPY_MODEL_e90754fdbc6640078023d61cbad8fee6","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"cf25bae67a5844d4b45f29afe724aea5":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_7a80cd9878d94f0bba5c91c3a25615f8","placeholder":"​","style":"IPY_MODEL_6f4ca38ab53147c597706b96040f9629","value":""}},"025b1e3343094c9bbbea51ca633af1c3":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_43a9631146ba49deba6fe314f2b8cd94","style":"IPY_MODEL_af6d0f8ff4fb444ab26e8c846b89752f","value":true}},"8f5cee23efdd47e4a33dc145619cbbb9":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_2ffbeecf4dcd4501a890f3622f75ef5b","style":"IPY_MODEL_70b5851e60f948819edc5182c7e9c1c4","tooltip":""}},"478ea8bae8664b5182726838b6cc402c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_854f8364a806432b9689ca855a2c8aca","placeholder":"​","style":"IPY_MODEL_5761818bc797479fa5f832772a04c635","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"21ed730edd9445fda7dd3f03f5c11222":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"5ff7c671e7564bcdb1d2b9d5ee3019c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e90754fdbc6640078023d61cbad8fee6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a80cd9878d94f0bba5c91c3a25615f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f4ca38ab53147c597706b96040f9629":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43a9631146ba49deba6fe314f2b8cd94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af6d0f8ff4fb444ab26e8c846b89752f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ffbeecf4dcd4501a890f3622f75ef5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70b5851e60f948819edc5182c7e9c1c4":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"854f8364a806432b9689ca855a2c8aca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5761818bc797479fa5f832772a04c635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install -q optuna datasets evaluate\n","!pip install -U bitsandbytes"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9BK_6qkWJK7","executionInfo":{"status":"ok","timestamp":1745187042152,"user_tz":240,"elapsed":85289,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"55718fab-d56a-4d59-9887-c7a8a3932825"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/386.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/231.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mCollecting bitsandbytes\n","  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n","Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AIrzDnckgabB","executionInfo":{"status":"ok","timestamp":1745187058419,"user_tz":240,"elapsed":16263,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"outputs":[],"source":["from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import json\n","import os\n","import shutil\n","\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","import transformers\n","import re\n","\n","import optuna\n","import evaluate\n","\n","import pickle\n","\n","from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n","\n","from datasets import Dataset\n","from transformers import (AutoTokenizer,\n","                          AutoModelForCausalLM,\n","                          BitsAndBytesConfig,\n","                          Trainer,\n","                          TrainingArguments,\n","                          TrainerCallback,\n","                          DataCollatorForMultipleChoice,\n","                          GenerationConfig)\n","\n","os.environ['WANDB_DISABLED'] = 'true'"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# authenticating to empty trash during grid search\n","from google.colab import auth\n","auth.authenticate_user()\n","from googleapiclient.discovery import build\n","drive_service = build('drive', 'v3')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJ2KBJUtgf4q","executionInfo":{"status":"ok","timestamp":1745187087326,"user_tz":240,"elapsed":28905,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"3e34d452-9030-4dff-86fd-879d708cfdde"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# training data path\n","\n","version = 3 # version of model to save\n","\n","path_to_nlu_dir = \"/content/drive/MyDrive/Master's/Second Year Grad/NLU/NLU_FinalProject/\"\n","data_dir = path_to_nlu_dir+\"Data/JSONL_Formatted/\"\n","\n","train_path = \"RACE-H/sftc_RACE-H_v1_trn.jsonl\"\n","val_path = \"RACE-H/sftc_RACE-H_v1_dev.jsonl\"\n","\n","data_name = 'RACE-H'\n","save_dir = path_to_nlu_dir+\"Results/ft_Results/\"\n","\n","if not os.path.exists(save_dir):\n","  os.mkdir(save_dir)\n","\n","model_name = \"openai-community/gpt2-xl\"\n","\n","sftc = True if 'sftc' in train_path else False\n","\n","# number of layers to train (taken from the last layers)\n","# if none, trains all layers\n","NUM_TRAINING_LAYERS = 2"],"metadata":{"id":"E4CUMvZNgwkK","executionInfo":{"status":"ok","timestamp":1745187090251,"user_tz":240,"elapsed":2924,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Load in tokenizer/model using LoRA/PEFT"],"metadata":{"id":"gRjalSadSiXP"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.truncation_side = 'left'\n","\n","# setting max_new_tokens = 0\n","gen_config = GenerationConfig.from_pretrained(model_name)\n","gen_config.max_new_tokens = 0\n","\n","# QUANTIZATION (4bit)\n","bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","def init_model():\n","  model = AutoModelForCausalLM.from_pretrained(model_name,\n","                                               #quantization_config=bnb_config,\n","                                               device_map=None)\n","\n","  # freeze params\n","  for param in model.parameters():\n","    param.requires_grad = False\n","\n","  ''' currently not used\n","  if NUM_TRAINING_LAYERS is not None:\n","    # unfreeze last layer(s)\n","    for block in model.transformer.h[-NUM_TRAINING_LAYERS:]:\n","      for param in block.parameters():\n","        param.requires_grad = True\n","\n","    # unfreeze final layer norm + output head\n","    for param in model.transformer.ln_f.parameters():\n","      param.requires_grad = True\n","    for param in model.lm_head.parameters():\n","      param.requires_grad = True\n","  '''\n","\n","  # PEFT model\n","  if 'gpt' in model_name:\n","    lora_modules = ['c_attn', 'c_fc', 'c_proj', 'wpe', 'wte']\n","  elif 'llama' in model_name:\n","    lora_modules = ['q_proj', 'v_proj', 'k_proj', 'o_proj']\n","\n","  r = 16\n","  config = LoraConfig(\n","        r=r,\n","        lora_alpha=r,\n","        lora_dropout=0.02,\n","        target_modules=lora_modules,\n","        bias=\"none\",\n","        task_type='CAUSAL_LM',\n","  )\n","\n","  model = get_peft_model(model, config)\n","  model.generation_config = gen_config\n","\n","  trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","  total = sum(p.numel() for p in model.parameters())\n","  print(f\"Trainable params: {trainable} / {total} ({100 * trainable / total:.2f}%)\\n\")\n","\n","  return model.to('cuda')\n","\n","data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":209,"referenced_widgets":["98d07f484208497490ed71bc22742de8","591f4b5def524090b44c9cc6c30e1222","dc8fa108ad974c90a7fd0c13d2fffcf5","9ff0fdceb5914a1d8a8c0c75cd927cf5","1a504401fb7148728c7bfc142b45cdf0","5864ddce9d47402db087bebe04c7066a","49470c3e8e524e2d9e6e96ccea6061e5","bec11c0c352e41b682d90593999f034a","0ca4fbb0e5f84896be9e53c546653fd2","9e50b5bf41a844dcbf82da915ee6b898","0f1ed7677a004063ae559b93e08821fd","22295b0edf4f491ebd53ca0144ff0511","e693d74559364200ac5440082dd975dd","2f536c8170f747dc8dd4875c9fe8c31f","0e806e5813054592a00db084309b44da","6cb922ff5489452f9df016d046c3eb23","e0df2c5c63e14cd9a875cb93be3db86a","ab1a8c72770a464fa0334f2c83f5106e","c1f6caf4d21447e7ba6938937508527f","a4f13dde07b24ca88242724a3b95a104","74ab2becd4e3420eaaa3ed4d3632bac5","7eb8985b176c4aaa8b6bc17db318f708","78a8d261c4b3414194ac142bc2623543","a1a97e6748084957b6b4d5e3f142ebb7","8d40eac84fa54ae7b985670224565f25","ab2f32ffd85a4b74979c7594e089e2d9","95257940a1bc49e9bfe3c3c610f95496","036b467f58ec4a7b85d9266179b278fc","321bdecb600c4b55a82f2ffe2da5ec15","b2802bf325124d37a201e21e134a36c3","67d207297da94e83bc9e679dacd647f9","53f28a2da46040f5b2c6c6df6825c128","89be7289dc2244929050496bb93cebd5","6e7f1216a52a427eb8b56cb89c5a6e83","25bf264c58d94ab5b9f941dbd9d4d1da","658942d3e5ee446c92f3b9ec6ecbfad7","2a6775e4c3e14e76a45e410e85da9623","468d65e504ae4934bca7ae9c58cd55b0","5f43f7de436c46a1b70bbae51fadc4cd","ab348b677b414c168867d131549a3d04","a86460a5224542bdae6ce723156880a4","a4d50cab8eac4adebe9f7e996516743a","0d145a61b96d493898310231aa4df629","018e0cd1a47e48e9984fdba26b1b2682","7bdb09cdfad1469092b7c33d5820f556","ff44f9aec8d248d593dd69f77cea5211","40fd62266b8846e7a53edaf3e875a505","82990f6207b14da2a4f91fbfbf9461fd","73199331c5294612895c55159505de5f","919a14c564fd4be4aed8a14a6ecab92c","dfba311496654a12948fd47e70f9fc24","f551e29be04a4a37a0f6d46dfe08865c","a4810a63b2644801aafdee6a14d02d0e","be7ecc5977924ba7917a51c5358b709a","e459a60ad4234b4aaee85d86297d82bd","2da00f9a91c54a4aa1c732826241f112","61616548e3264781921ea15d591ddca8","30dd36403e77448bb44d2eff33c454ce","12479fe0c3b8405a99e31f4ed14afcf7","277514f546cf44bead7039904e8d9d6c","a05f1ca2d15247f2b1bc16094721d8e6","d1fc8584d65c455e8158ab4299fa8343","5212ec8600af4a4198f8769dc6811c5e","a6445107cddc44a68b09428779a64441","88f2c5084a174f88921ea3f17d7d0fc7","3b8b141f5648485e94e1f69556eb2945"]},"id":"t2yKO9TeSjna","executionInfo":{"status":"ok","timestamp":1745187095830,"user_tz":240,"elapsed":5578,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"e7478474-3903-4f2f-ce0f-869ba42e7d7b"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98d07f484208497490ed71bc22742de8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22295b0edf4f491ebd53ca0144ff0511"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a8d261c4b3414194ac142bc2623543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e7f1216a52a427eb8b56cb89c5a6e83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bdb09cdfad1469092b7c33d5820f556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da00f9a91c54a4aa1c732826241f112"}},"metadata":{}}]},{"cell_type":"markdown","source":["Load and Process Training/Validation Dataset"],"metadata":{"id":"5Xurzr1fHTRy"}},{"cell_type":"code","source":["def create_input(line, sys_prompt='', fs_demos=''):\n","  pqa = [f\"{fs_demos}Q: {line['context']} {line['question']}\\nA:{sys_prompt} {line[i]}\"\n","          for i in ['answerA', 'answerB', 'answerC', 'answerD']]\n","  label = 'ABCD'.index(line['correct'])\n","\n","  # tokenize input\n","  tokenized_input = tokenizer(pqa, padding='max_length', truncation=True, max_length=512)\n","\n","  return {'input_ids': tokenized_input['input_ids'],\n","          'attention_mask': tokenized_input['attention_mask'],\n","          'label': label}"],"metadata":{"id":"hyGupLIQIdWU","executionInfo":{"status":"ok","timestamp":1745187095844,"user_tz":240,"elapsed":13,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# training data\n","with open(data_dir + train_path, 'r') as f:\n","  train_data_raw = [json.loads(line) for line in f]\n","\n","train_data = Dataset.from_list([create_input(train_data_raw[i]) for i in tqdm(range(919))])\n","\n","# val data\n","with open(data_dir + val_path, 'r') as f:\n","  val_data_raw = [json.loads(line) for line in f]\n","\n","val_data = Dataset.from_list([create_input(val_data_raw[i]) for i in tqdm(range(131))])\n","\n","print(f'\\nTraining Size = {len(train_data)}')\n","print(f'Validation Size = {len(val_data)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujuJHqjhHSZA","executionInfo":{"status":"ok","timestamp":1745187109314,"user_tz":240,"elapsed":13469,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"8d25da72-a90c-4aac-db25-12b1d1ea93c4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 919/919 [00:02<00:00, 397.94it/s]\n","100%|██████████| 131/131 [00:00<00:00, 435.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Training Size = 919\n","Validation Size = 131\n"]}]},{"cell_type":"code","source":["# training example\n","print(train_data_raw[0])\n","print(np.array(train_data[0]['input_ids']).shape)\n","print(np.array(train_data[0]['attention_mask']).shape)\n","print(train_data[0]['label'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wfi0YJqLXVPV","executionInfo":{"status":"ok","timestamp":1745187109336,"user_tz":240,"elapsed":11,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"301c1229-045b-4eb7-cc51-93296561e7f1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{'context': 'You may have heard the term \" the American Dream \" . In 1848 , James W. Marshall found [[HL]] gold [[/HL]] in California and people began having golden dreams . That 19th century \" American Dream \" motivated    the [[HL]] Gold [[/HL]] Rush and [[HL]] gave [[/HL]] California its nickname of the \" Golden State \" . The American Dream drove not only 1800s [[HL]] gold [[/HL]] - rush prospectors but also waves of immigrants throughout that century and the next . People from Europe , and a large number of [[HL]] Chinese [[/HL]] , arrived in the US in the 19th century hoping that in America they would find [[HL]] gold [[/HL]] in the streets . But most , instead , worked as railroad labourers . They [[HL]] created [[/HL]] the [[HL]] oldest [[/HL]] [[HL]] Chinatown [[/HL]] , in [[HL]] San [[/HL]] [[HL]] Francisco [[/HL]] , and [[HL]] gave [[/HL]] the [[HL]] city [[/HL]] a [[HL]] Chinese [[/HL]] [[HL]] name [[/HL]] \" the [[HL]] old [[/HL]] [[HL]] gold [[/HL]] [[HL]] hill [[/HL]] \" . In the 20th century , some critics said that it was no longer possible to become prosperous through determination and hard work . Unfair education for students from poor families and racial discrimination almost made the American Dream a nightmare . Then , in the 1990s , California saw a new wave of dreamers in Silicon Valley . People poured their energy into the Internet . This new chapter of the American Dream attracted many business people and young talents from China and India to form start - ups and seek fortunes in America . Better pay , a nice house , and a rising standard of living will always be attractive . However , the new American Dream is no longer just about money . It encourages Americans to consume wisely to protect the environment , improve the quality of life , and promote social justice . The Governor of California , Arnold Schwarzenegger , has become the model of the new American Dream . After years of hard work , he grew from a poor young man from Austria into a movie superstar and then governor . Many people hope his story can save the American Dream and give California a brighter future .', 'question': \"They created _ oldest Chinatown , in San Francisco , and gave the city a Chinese name `` the old gold hill '' .\", 'answerA': 'railroad', 'answerB': 'labourers', 'answerC': 'families', 'answerD': 'the', 'correct': 'D'}\n","(4, 512)\n","(4, 512)\n","3\n"]}]},{"cell_type":"markdown","source":["Set up `Trainer` class and hyperparameter tuning"],"metadata":{"id":"oHp2V-p1HXGp"}},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id,\n","                              reduction=\"none\")\n","accuracy = evaluate.load('accuracy')\n","\n","def compute_metrics(eval_pred):\n","  logits, labels, input = eval_pred\n","\n","  with torch.no_grad():\n","    if isinstance(logits, np.ndarray):\n","      logits = torch.tensor(logits)\n","    if isinstance(labels, np.ndarray):\n","      labels = torch.tensor(labels)\n","    if isinstance(input, np.ndarray):\n","      input = torch.tensor(input)\n","\n","    batch_size, num_choices, seq_len = input.shape\n","    input_ids_flat = input.reshape(batch_size*num_choices, -1)\n","    logits = logits.reshape(batch_size*num_choices, seq_len, -1)\n","\n","    # Shift logits and target\n","    logits = logits[:, :-1, :]         # shape: (batch_size * 4, seq_len-1, vocab)\n","    targets = input_ids_flat[:, 1:]    # shape: (batch_size * 4, seq_len-1)\n","\n","    # per choice loss\n","    per_token_loss = loss_fn(logits.reshape(-1, logits.size(-1)), # shape: (batch_size * 4 * seq_len-1, vocab)\n","                             targets.reshape(-1))                 # shape: (batch_size * 4 * seq_len-1)\n","    per_token_loss = per_token_loss.reshape(batch_size, num_choices, -1)  # shape: (batch_size, 4, seq_len-1)\n","\n","    per_choice_loss = per_token_loss.sum(dim=-1) # shape: (batch_size, 4)\n","\n","    preds = torch.argmin(per_choice_loss, dim=-1)\n","\n","  acc = accuracy.compute(predictions=preds, references=labels)\n","\n","  return acc"],"metadata":{"id":"X-8ADvc2eFJb","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["80fb81bef91442a8ab95c5b656a760fd","0173adad0e2a4a8da83f39cac34d0c90","3aa6ebdaa14f45d5bf8a6578a8d372f8","cfc268ef4e6b42e59b5af120b48cb671","5dc6061025984a19909c4d5302b67d37","ea559bede34d4be88281f7fbb19f1101","a3a78f2385aa443189f3e4e0099fd166","c12cb7bec3fc4808b5d3c0fd05e76d33","2131fec87b56439caa0e37125ec64d15","1de6c1146aa74d82b90e8cf9fc132337","91947b908b604cd08d89f1e6aeba43ff"]},"executionInfo":{"status":"ok","timestamp":1745187110810,"user_tz":240,"elapsed":1470,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"256226d8-dcc3-4a21-d238-e592799cb59b"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80fb81bef91442a8ab95c5b656a760fd"}},"metadata":{}}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=f\"{save_dir}checkpoints/\",\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    fp16=True,\n","    eval_accumulation_steps=1,\n","    eval_strategy='epoch',\n","    save_total_limit=1,\n","    logging_strategy='epoch',\n","    include_for_metrics = [\"inputs\"],\n","    prediction_loss_only=True\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOrW7qm1HcP6","executionInfo":{"status":"ok","timestamp":1745187110860,"user_tz":240,"elapsed":49,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"6756dc30-f1ed-4317-91b1-c9312a63ca38"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}]},{"cell_type":"code","source":["class CustomTrainer(Trainer):\n","  def compute_loss(self, model, inputs,\n","                   return_outputs=False,\n","                   num_items_in_batch=None):\n","    input_ids = inputs[\"input_ids\"]         # shape: (batch_size, 4, seq_len)\n","    attention_mask = inputs[\"attention_mask\"]\n","    labels = inputs[\"labels\"]               # shape: (batch_size,)\n","\n","    batch_size, num_choices, seq_len = input_ids.shape\n","    input_ids = input_ids.reshape(batch_size * num_choices, seq_len)\n","    attention_mask = attention_mask.reshape(batch_size * num_choices, seq_len)\n","\n","    # flatten to single batch dimension\n","    input_ids_flat = input_ids.reshape(batch_size*num_choices, -1)\n","    attention_mask_flat = attention_mask.reshape(batch_size*num_choices, -1)\n","\n","    # Forward pass\n","    outputs = model(input_ids=input_ids_flat, attention_mask=attention_mask_flat)\n","    logits = outputs.logits  # shape: (batch_size * 4, seq_len, vocab)\n","\n","    # Shift logits and target\n","    logits = logits[:, :-1, :]         # shape: (batch_size * 4, seq_len-1, vocab)\n","    targets = input_ids_flat[:, 1:]    # shape: (batch_size * 4, seq_len-1)\n","\n","    # per choice loss\n","    per_token_loss = loss_fn(logits.reshape(-1, logits.size(-1)), # shape: (batch_size * 4 * seq_len-1, vocab)\n","                             targets.reshape(-1))                 # shape: (batch_size * 4 * seq_len-1)\n","    per_token_loss = per_token_loss.reshape(batch_size, num_choices, -1)  # shape: (batch_size, 4, seq_len-1)\n","\n","    per_choice_loss = per_token_loss.sum(dim=-1) # shape: (batch_size, 4)\n","\n","    # overall loss (smaller loss is better)\n","    total_loss_fn = nn.CrossEntropyLoss() # applies mean reduction by default (across batch)\n","    final_loss = total_loss_fn(-per_choice_loss, labels)\n","\n","    return (final_loss, outputs) if return_outputs else final_loss\n","\n","\n","trainer = CustomTrainer(\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    model_init = init_model\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230,"referenced_widgets":["e9e6acc66b4b41558a982feb58d08667","a59f7f9b753b40c6b9cf6855ed123a10","1945731621e54137bc0ae16c4e8cde2b","40b3c98c3ea34e3494949b4357d13a09","d7cf226ecf204324b5d2ad490af8d842","cf6255e20e524543884b57e7f723b012","6d66e498ba93420d8774b0bf56eeda3c","25bfabb1ee074435b958d8cb5d1de3cf","58353711b5c9440489c7ab773dfeb321","3ffd57c065154e8dbc98be217dc848f2","5ab2abe6beca427cbea7612705bc0daf"]},"id":"N6jLsYN8NK2y","executionInfo":{"status":"ok","timestamp":1745187136495,"user_tz":240,"elapsed":25631,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"a767f26d-5c8d-411f-8083-8157888509bb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-4bf1845d2f3d>:39: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e6acc66b4b41558a982feb58d08667"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]}]},{"cell_type":"code","source":["test = trainer.predict(val_data.select(range(2)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"id":"Aanh6FbyPu3O","executionInfo":{"status":"ok","timestamp":1745187137453,"user_tz":240,"elapsed":972,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"3b9bfdf7-a565-430e-bef1-520a6e143d86"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"1WLhhixY-LEc","outputId":"69e8a0f9-81ea-4c40-ad98-d3d45d770597","executionInfo":{"status":"ok","timestamp":1745187155438,"user_tz":240,"elapsed":17979,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 3.4317562580108643,\n"," 'eval_model_preparation_time': 0.0251,\n"," 'eval_runtime': 17.942,\n"," 'eval_samples_per_second': 7.301,\n"," 'eval_steps_per_second': 7.301}"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# optuna callback\n","best_score = float('inf')\n","best_run_dir = None\n","def OptunaCallback(study, trial):\n","  global best_score, best_run_dir\n","\n","  curr_score = trial.value\n","  curr_run_dir = f\"{save_dir}checkpoints/run-{trial.number}\"\n","\n","  if not np.isnan(curr_score) and curr_score < best_score:\n","    if best_run_dir is not None and os.path.exists(best_run_dir):\n","      print(f'Trial {trial.number} is new best. Deleting previous best at {best_run_dir}')\n","      shutil.rmtree(best_run_dir)\n","\n","    best_score = curr_score\n","    best_run_dir = curr_run_dir\n","  elif not np.isnan(curr_score):\n","    if os.path.exists(curr_run_dir):\n","      print(f'Trial {trial.number} not best. Deleting...')\n","      shutil.rmtree(curr_run_dir)\n","\n","  # empty trash bin\n","  drive_service.files().emptyTrash().execute()\n","\n","def objective(trial):\n","  training_args = TrainingArguments(\n","    output_dir=f\"{save_dir}checkpoints/run-{trial.number}\",\n","    learning_rate = trial.suggest_categorical(\"learning_rate\", [1e-3, 1e-4, 5e-5]),\n","    num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [2, 3, 5]),\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    fp16=True,\n","    eval_accumulation_steps=1,\n","    eval_strategy='epoch',\n","    save_total_limit=1,\n","    logging_strategy='epoch',\n","    include_for_metrics = [\"inputs\"],\n","    prediction_loss_only=True\n","  )\n","\n","  trainer = CustomTrainer(\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n","    model_init = init_model\n","  )\n","\n","  trainer.train()\n","  return trainer.evaluate()['eval_loss']"],"metadata":{"id":"a36pUE08W03k","executionInfo":{"status":"ok","timestamp":1745187155464,"user_tz":240,"elapsed":19,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Train and save model"],"metadata":{"id":"DW5KIRRKHaCP"}},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","notebook_login()"],"metadata":{"id":"yYGSwxz584OG","colab":{"base_uri":"https://localhost:8080/","height":359,"referenced_widgets":["4724eda40e0842378378adb62cbd6a9d","e19ef2ed343f4756b9f4d5765e4f5877","cf25bae67a5844d4b45f29afe724aea5","025b1e3343094c9bbbea51ca633af1c3","8f5cee23efdd47e4a33dc145619cbbb9","478ea8bae8664b5182726838b6cc402c","21ed730edd9445fda7dd3f03f5c11222","5ff7c671e7564bcdb1d2b9d5ee3019c5","e90754fdbc6640078023d61cbad8fee6","7a80cd9878d94f0bba5c91c3a25615f8","6f4ca38ab53147c597706b96040f9629","43a9631146ba49deba6fe314f2b8cd94","af6d0f8ff4fb444ab26e8c846b89752f","2ffbeecf4dcd4501a890f3622f75ef5b","70b5851e60f948819edc5182c7e9c1c4","854f8364a806432b9689ca855a2c8aca","5761818bc797479fa5f832772a04c635"]},"executionInfo":{"status":"ok","timestamp":1745187155592,"user_tz":240,"elapsed":124,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"b5b3db72-3cd4-4ac1-d553-63d463b6fb61"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4724eda40e0842378378adb62cbd6a9d"}},"metadata":{}}]},{"cell_type":"code","source":["# Train and save the best hyperparameters\n","\n","search_space = {'learning_rate': [1e-3, 1e-4, 5e-5],\n","                    'num_train_epochs': [2,3,5]}\n","\n","study = optuna.create_study(\n","    direction=\"minimize\",\n","    sampler=optuna.samplers.GridSampler(search_space),\n","    load_if_exists=True\n",")\n","\n","study.optimize(objective, n_trials=9, callbacks=[OptunaCallback])"],"metadata":{"id":"kQM9tLrTIAv7","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1745197320429,"user_tz":240,"elapsed":10164836,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"f8691a68-73e4-48d6-e1f1-ceeee053602e"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 22:12:35,355] A new study created in memory with name: no-name-1dbfea8f-c088-466e-ac28-4578fb22f0e6\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2757' max='2757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2757/2757 16:29, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.830200</td>\n","      <td>1.857530</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.772700</td>\n","      <td>0.570348</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.226500</td>\n","      <td>0.485175</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 22:29:30,778] Trial 0 finished with value: 0.4851752817630768 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 3}. Best is trial 0 with value: 0.4851752817630768.\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4595' max='4595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4595/4595 27:18, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>63.136100</td>\n","      <td>17.319670</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>26.434900</td>\n","      <td>5.742028</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>7.764900</td>\n","      <td>5.369783</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.000000</td>\n","      <td>5.369783</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.000000</td>\n","      <td>5.369783</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 22:57:15,859] Trial 1 finished with value: 5.369783401489258 and parameters: {'learning_rate': 0.001, 'num_train_epochs': 5}. Best is trial 0 with value: 0.4851752817630768.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 1 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2757' max='2757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2757/2757 16:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>13.620600</td>\n","      <td>4.630993</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>7.130400</td>\n","      <td>4.555271</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>6.298000</td>\n","      <td>4.965110</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 23:14:16,556] Trial 2 finished with value: 4.9651103019714355 and parameters: {'learning_rate': 0.001, 'num_train_epochs': 3}. Best is trial 0 with value: 0.4851752817630768.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 2 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2757' max='2757' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2757/2757 16:31, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>6.475100</td>\n","      <td>0.623745</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.967900</td>\n","      <td>0.332655</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.775100</td>\n","      <td>0.531771</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 23:31:15,419] Trial 3 finished with value: 0.5317707061767578 and parameters: {'learning_rate': 0.0001, 'num_train_epochs': 3}. Best is trial 0 with value: 0.4851752817630768.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 3 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4595' max='4595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4595/4595 27:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.709600</td>\n","      <td>1.691523</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.547900</td>\n","      <td>0.524607</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.463300</td>\n","      <td>0.298625</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.906400</td>\n","      <td>0.287697</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.692300</td>\n","      <td>0.309282</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-20 23:59:22,471] Trial 4 finished with value: 0.30928248167037964 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 5}. Best is trial 4 with value: 0.30928248167037964.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 4 is new best. Deleting previous best at /content/drive/MyDrive/Master's/Second Year Grad/NLU/NLU_FinalProject/Results/ft_Results/checkpoints/run-0\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1838' max='1838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1838/1838 11:05, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>7.980100</td>\n","      <td>1.976580</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.504600</td>\n","      <td>1.142118</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-21 00:10:55,299] Trial 5 finished with value: 1.1421178579330444 and parameters: {'learning_rate': 5e-05, 'num_train_epochs': 2}. Best is trial 4 with value: 0.30928248167037964.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 5 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1838' max='1838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1838/1838 11:02, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>6.691800</td>\n","      <td>0.899303</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.492900</td>\n","      <td>0.463933</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-21 00:22:24,990] Trial 6 finished with value: 0.4639325439929962 and parameters: {'learning_rate': 0.0001, 'num_train_epochs': 2}. Best is trial 4 with value: 0.30928248167037964.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 6 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1838' max='1838' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1838/1838 11:03, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>22.025100</td>\n","      <td>9.710381</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>5.880100</td>\n","      <td>3.312644</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-21 00:33:54,675] Trial 7 finished with value: 3.3126440048217773 and parameters: {'learning_rate': 0.001, 'num_train_epochs': 2}. Best is trial 4 with value: 0.30928248167037964.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 7 not best. Deleting...\n"]},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-14-48f14555f72a>:90: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  trainer = CustomTrainer(\n","/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"stream","name":"stdout","text":["Trainable params: 20532496 / 1578143696 (1.30%)\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4595' max='4595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4595/4595 27:39, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>6.418600</td>\n","      <td>0.961039</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.230800</td>\n","      <td>0.458596</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.696700</td>\n","      <td>0.584465</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.501200</td>\n","      <td>0.330689</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.259900</td>\n","      <td>0.334988</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/peft/utils/other.py:716: UserWarning: Unable to fetch remote file due to the following error (ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 4ba2108b-16b4-4a3b-897e-2afdcc7a64e7)') - silently ignoring the lookup for the file config.json in openai-community/gpt2-xl.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:246: UserWarning: Could not find a config file in openai-community/gpt2-xl - will assume that the vocabulary was not modified.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='131' max='131' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [131/131 00:17]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-04-21 01:01:59,963] Trial 8 finished with value: 0.3349880278110504 and parameters: {'learning_rate': 0.0001, 'num_train_epochs': 5}. Best is trial 4 with value: 0.30928248167037964.\n"]},{"output_type":"stream","name":"stdout","text":["Trial 8 not best. Deleting...\n"]}]},{"cell_type":"code","source":["N = len(train_data)*study.best_trial.params['num_train_epochs']\n","checkpoint_dir = os.path.join(save_dir, 'checkpoints', f\"run-{study.best_trial.number}\", f\"checkpoint-{N}\")\n","\n","print(checkpoint_dir)\n","\n","model_dir = f\"Salm00n/{model_name.split('/')[-1]}_{data_name}_v{version}\"\n","print(model_dir)\n","\n","os.path.exists(checkpoint_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADEeWtGYQtSX","executionInfo":{"status":"ok","timestamp":1745197337061,"user_tz":240,"elapsed":44,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}},"outputId":"1de6eb68-dbc2-4040-f33b-708ef79b991c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master's/Second Year Grad/NLU/NLU_FinalProject/Results/ft_Results/checkpoints/run-4/checkpoint-4595\n","Salm00n/gpt2-xl_RACE-H_v3\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Save best model to HuggingFace account\n","\n","if not sftc:\n","  # load in best model with same PEFT/quantization\n","  # Note: uses last saved checkpoint from best parameter trial\n","  config = PeftConfig.from_pretrained(checkpoint_dir)\n","  base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n","                                              #quantization_config=bnb_config,\n","                                              device_map='auto')\n","  model = PeftModel.from_pretrained(base_model, checkpoint_dir, torch_dtype=torch.float16)\n","\n","  # push best model to hugging face\n","  model.push_to_hub(model_dir)\n","\n","else:\n","  config = PeftConfig.from_pretrained(checkpoint_dir)\n","  base_model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n","                                              #quantization_config=bnb_config,\n","                                              device_map='auto')\n","  model = PeftModel.from_pretrained(base_model, checkpoint_dir, torch_dtype=torch.float16,\n","                                    is_trainable=True)\n","\n","  # load in second dataset\n","\n","  # training data\n","  train_path_orig = data_dir + train_path.replace('sftc_','')\n","  print(f'Second Training Set at {train_path_orig}')\n","  with open(train_path_orig, 'r') as f:\n","    train_data_raw = [json.loads(line) for line in f]\n","\n","  train_data = Dataset.from_list([create_input(train_data_raw[i]) for i in tqdm(range(919))])\n","\n","  # val data\n","  val_path_orig = data_dir + val_path.replace('sftc_','')\n","  print(f'Second Validation Set at {val_path_orig}')\n","  with open(val_path_orig, 'r') as f:\n","    val_data_raw = [json.loads(line) for line in f]\n","\n","  val_data = Dataset.from_list([create_input(val_data_raw[i]) for i in tqdm(range(131))])\n","\n","  training_args = TrainingArguments(\n","    output_dir = model_dir,\n","    learning_rate = study.best_trial.params['learning_rate'],\n","    num_train_epochs = study.best_trial.params['num_train_epochs'],\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    fp16=True,\n","    eval_accumulation_steps=1,\n","    eval_strategy='epoch',\n","    save_total_limit=1,\n","    logging_strategy='epoch',\n","    include_for_metrics = [\"inputs\"],\n","    prediction_loss_only=True\n","  )\n","\n","  trainer = CustomTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    args=training_args,\n","    train_dataset=train_data,\n","    eval_dataset=val_data,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","  )\n","\n","  trainer.train()\n","  # push best model to hugging face\n","  trainer.push_to_hub(model_dir)"],"metadata":{"id":"vs2PpJSMhCTD","executionInfo":{"status":"aborted","timestamp":1745153034671,"user_tz":240,"elapsed":28,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"wwCinnfIGfee","executionInfo":{"status":"aborted","timestamp":1745153034672,"user_tz":240,"elapsed":1191816,"user":{"displayName":"Simone Gabrielle Rittenhouse","userId":"06875084696471888875"}}},"execution_count":null,"outputs":[]}]}